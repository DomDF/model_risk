@article{Ainsworth2008,
   abstract = {This paper first briefly summarises the existing methods in the low-temperature fracture assessment procedure, R6, and the high-temperature procedure, R5, for treating the effects of secondary stresses on structural integrity. Recently, there have been a number of developments, which identify the way forward for these procedures. A modified J-integral definition has been derived, which is path independent for cases of proportional and non-proportional loading and is ideal for evaluating the crack driving force for defects in secondary and residual stress fields. Results of finite element analysis are presented that show that the use of the modified J-integral can lead to a lower crack driving force for secondary stresses than current simplified R6 methods. More detailed calculations have assessed the effects on fracture of a slowly growing crack and constraint effects associated with secondary stresses. Preliminary results are presented, showing the long-term potential of more advanced methods in providing significant benefits in structural integrity assessments. For high-temperature applications, the paper presents methods for calculating the relaxation of secondary stresses due to both creep strain and creep crack growth, extending current methods in R5 that only allow for relaxation due to creep strain. Related work addressing the combined effects of plasticity and creep on relaxation of the crack tip fields is also presented and the results are illustrated for a typical geometry and loading. © 2007 Elsevier Ltd. All rights reserved.},
   author = {R. A. Ainsworth and D. G. Hooton},
   doi = {10.1016/j.ijpvp.2007.10.003},
   isbn = {0308-0161},
   issn = {03080161},
   journal = {International Journal of Pressure Vessels and Piping},
   keywords = {Creep,Fracture,R5,R6,Residual stress,Secondary stress},
   title = {R6 and R5 procedures: The way forward},
   year = {2008}
}
@book{Gelman2014,
   abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
   author = {Andrew Gelman and John B B Carlin and Hal S S Stern and Donald B B Rubin},
   doi = {10.1007/s13398-014-0173-7.2},
   edition = {3rd},
   editor = {Francesca Dominici and Julian J. Faraway and Martin Tanner and Jim Zidek},
   isbn = {9781439840955},
   issn = {1467-9280},
   pages = {675},
   pmid = {25052830},
   publisher = {Chapman & Hall / CRC},
   title = {Bayesian Data Analysis},
   year = {2014}
}
@article{Gelman2020b,
   abstract = {Every philosophy has holes, and it is the responsibility of proponents of a philosophy to point out these problems. Here are a few holes in Bayesian data analysis: (1) the usual rules of conditional probability fail in the quantum realm, (2) flat or weak priors lead to terrible inferences about things we care about, (3) subjective priors are incoherent, (4) Bayes factors fail in the presence of flat or weak priors, (5) for Cantorian reasons we need to check our models, but this destroys the coherence of Bayesian inference. Some of the problems of Bayesian statistics arise from people trying to do things they shouldn't be trying to do, but other holes are not so easily patched. In particular, it may be a good idea to avoid flat, weak, or conventional priors, but such advice, if followed, would go against the vast majority of Bayesian practice and requires us to confront the fundamental incoherence of Bayesian inference. This does not mean that we think Bayesian inference is a bad idea, but it does mean that there is a tension between Bayesian logic and Bayesian workflow which we believe can only be resolved by considering Bayesian logic as a tool, a way of revealing inevitable misfits and incoherences in our model assumptions, rather than as an end in itself.},
   author = {Andrew Gelman and Yuling Yao},
   doi = {10.1088/1361-6471/abc3a5},
   issn = {0954-3899},
   issue = {1},
   journal = {Journal of Physics G: Nuclear and Particle Physics},
   pages = {014002},
   publisher = {IOP Publishing},
   title = {Holes in bayesian statistics},
   volume = {48},
   year = {2020}
}
@book{Sutton2020,
   author = {Richard S. Sutton and Andrew G. Barto},
   edition = {Second},
   isbn = {9780262039246},
   journal = {Universitas Nusantara PGRI Kediri},
   publisher = {MIT press},
   title = {Reinforcement Learning An Introduction},
   volume = {01},
   year = {2020}
}
@misc{HealthandSafetyExecutiveHSE,
   author = {Health and Safety Executive},
   title = {ALARP "at a glance"},
   url = {https://www.hse.gov.uk/enforce/expert/alarpglance.htm}
}
@techReport{DNV2021a,
   author = {DNV},
   title = {DNV-SE-0474 Risk based verification},
   url = {https://standards.dnv.com/},
   year = {2021}
}
@article{Gelman2016,
   abstract = {In summary, I agree with most of the ASA’s statement on p-values but I feel that the problems are deeper, and that the solution is not to reform p-values or to replace them with some other statistical summary or threshold, but rather to move toward a greater acceptance of uncertainty and embracing of variation.},
   author = {Andrew Gelman},
   doi = {10.1080/00031305.2016.1154108},
   issn = {0003-1305},
   journal = {The American Statistician},
   pages = {1-2},
   title = {The problems with p-values are not just with p-values},
   year = {2016}
}
@misc{DSIT2024,
   author = {Department for Science Innovation & Technology},
   isbn = {978-1-5286-4565-2},
   month = {2},
   title = {Command Paper: CP 1019. A pro-innovation approach to AI regulation},
   url = {https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach},
   year = {2024}
}
@techReport{UKGovernment2023,
   author = {UK Government},
   keywords = {6.8258,Book,HMG,Management,Orange,Principles: Concepts: Design102,Risk},
   title = {The Orange Book. Management of Risk – Principles and Concepts},
   url = {https://www.gov.uk/government/publications/orange-book},
   year = {2023}
}
@techReport{HMTreasury2015,
   author = {HM Treasury},
   isbn = {978-1-910337-67-7},
   keywords = {978-1-910337-67-7,PU1740,The Aqua Book: guidance on producing quality analysis for government},
   month = {3},
   title = {The Aqua Book: guidance on producing quality analysis for government},
   url = {https://www.gov.uk/government/publications/the-aqua-book-guidance-on-producing-quality-analysis-for-government},
   year = {2015}
}
@techReport{PortsdownWest2014,
   author = {Dstl Portsdown West},
   title = {The probabilistic elicitation of subjective data UK OFFICIAL},
   year = {2014}
}
@techReport{FSA2009,
   author = {Financial Services Authority},
   title = {The Turner Review. A regulatory response to the global banking crisis},
   year = {2009}
}
@article{Totino2023,
   abstract = {In the last few years, extracting, analyzing and classifying welding defects in radiographic images received a great deal of attention in several industry manufacturing. Nowadays, computer vision affords considerable accuracy in many practical applications, but making automatic processes approachable also in this field is still a challenge. As an example, Convolutional Neural Networks (CNNs) are widely recognized as efficient and accurate classification structures, but, due to the limited availability of specific datasets, training a CNN to classify welding defects is not trivial. This paper presents a new dataset collecting 24,407 radiographic images related to several classes of welding defects: lack of penetration, cracks, porosity and no defect. The proposed dataset of welding defects in radiographic images is released freely to the research community. As an example of application, the dataset has been used to train a customized version of the SqueezeNet CNN obtaining a test accuracy higher than 93%.},
   author = {Benito Totino and Fanny Spagnolo and Stefania Perri},
   doi = {10.53375/ijecer.2023.320},
   issue = {1},
   journal = {International Journal of Electrical and Computer Engineering Research},
   month = {3},
   pages = {13-17},
   publisher = {International Journal of Electrical and Computer Engineering Research},
   title = {RIAWELC: A Novel Dataset of Radiographic Images for Automatic Weld Defects Classification},
   volume = {3},
   year = {2023}
}
@article{Perri2023,
   abstract = {This letter presents a Convolutional Neural Network (CNN), named WelDeNet, customized to classify welding defects, such as lack of penetration (LP), cracks (CR), porosity (PO) and no defect (ND), by inspecting digitalized radiographic images. A new dataset that collects 24,407 images representing welding defects is also presented. WelDeNet consists of 14 cascaded convolutional layers and achieves a test accuracy of 99.5 %. When hardware implemented within the Raspberry Pi 3B + board, WelDeNet exhibits an inference time of only 134 ms, with CPU and memory utilizations of just 51 % and 47 MB, thus offering a promising solution easy-to-integrate in a real industrial environment.},
   author = {Stefania Perri and Fanny Spagnolo and Fabio Frustaci and Pasquale Corsonello},
   doi = {10.1016/j.mfglet.2022.11.006},
   issn = {22138463},
   journal = {Manufacturing Letters},
   keywords = {Convolutional Neural Network,Dataset,Welding defect},
   month = {1},
   pages = {29-32},
   publisher = {Elsevier Ltd},
   title = {Welding defects classification through a Convolutional Neural Network},
   volume = {35},
   year = {2023}
}
@techReport{Letter11_7,
   author = {Board of Governors of the Federal Reserve System Office of the Comptroller of the Currency},
   keywords = {Basel II,advanced approach,back testing,conceptual soundness,developmental evidence,effective challenge,governance,model,model development,model risk,ongoing monitoring,outcomes analysis,pillar 2,risk management,sensitivity analysis,stress testing,validation,vendor models},
   title = {SR Letter 11-7 Supervisory Guidance on Model Risk Management},
   year = {2011}
}
@misc{Bates2024,
   author = {Lisa K. Bates},
   doi = {10.1080/14649357.2024.2423570},
   issn = {1470000X},
   journal = {Planning Theory and Practice},
   publisher = {Routledge},
   title = {A Computer Must Never Make a Planning Decision},
   year = {2024}
}
@inproceedings{Abid2021,
   abstract = {Understanding and explaining the mistakes made by trained models is critical to many machine learning objectives, such as improving robustness, addressing concept drift, and mitigating biases. However, this is often an ad hoc process that involves manually looking at the model's mistakes on many test samples and guessing at the underlying reasons for those incorrect predictions. In this paper, we propose a systematic approach, conceptual counterfactual explanations (CCE), that explains why a classifier makes a mistake on a particular test sample(s) in terms of human-understandable concepts (e.g. this zebra is misclassified as a dog because of faint stripes). We base CCE on two prior ideas: counterfactual explanations and concept activation vectors, and validate our approach on well-known pretrained models, showing that it explains the models' mistakes meaningfully. In addition, for new models trained on data with spurious correlations, CCE accurately identifies the spurious correlation as the cause of model mistakes from a single misclassified test sample. On two challenging medical applications, CCE generated useful insights, confirmed by clinicians, into biases and mistakes the model makes in real-world settings.},
   author = {Abubakar Abid and Mert Yuksekgonul and James Zou},
   booktitle = {39th International Conference on Machine Learning, PMLR},
   month = {6},
   pages = {66-88},
   title = {Meaningfully Debugging Model Mistakes using Conceptual Counterfactual Explanations},
   url = {http://arxiv.org/abs/2106.12723},
   year = {2021}
}
@inproceedings{Altmeyer2023,
   abstract = {We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.},
   author = {Patrick Altmeyer and Arie Van Deursen and Cynthia C S Liem},
   doi = {doi.org/10.21105/jcon.00130},
   booktitle = {JuliaCon Proceedings},
   keywords = {Algorithmic Recourse,Counterfactual Explana-tions,Explainable Artificial Intelligence,Julia},
   pages = {130},
   title = {Explaining Black-Box Models through Counterfactuals},
   year = {2023}
}
@inproceedings{Carr2023,
   abstract = {Safe exploration is a common problem in reinforcement learning (RL) that aims to prevent agents from making disastrous decisions while exploring their environment. A family of approaches to this problem assume domain knowledge in the form of a (partial) model of this environment to decide upon the safety of an action. A so-called shield forces the RL agent to select only safe actions. However, for adoption in various applications, one must look beyond enforcing safety and also ensure the applicability of RL with good performance. We extend the applicability of shields via tight integration with state-of-the-art deep RL, and provide an extensive, empirical study in challenging, sparse-reward environments under partial observability. We show that a carefully integrated shield ensures safety and can improve the convergence rate and final performance of RL agents. We furthermore show that a shield can be used to bootstrap state-of-the-art RL agents: they remain safe after initial learning in a shielded setting, allowing us to disable a potentially too conservative shield eventually.},
   author = {Steven Carr and Nils Jansen and Sebastian Junges and Ufuk Topcu},
   booktitle = {The Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)},
   keywords = {SRAI: Formal Methods for AI Systems: General,SRAI: Safe Decision Making Under Uncertainty: General,SRAI: Safe Learning: General},
   title = {Safe Reinforcement Learning via Shielding under Partial Observability},
   url = {www.aaai.org},
   year = {2023}
}
@article{DiFrancesco2025,
   abstract = {Novel methods of data collection and analysis can enhance traditional risk management practices that rely on expert engineering judgment and established safety records, specifically when key conditions are met: Analysis is linked to the decisions it is intended to support, standards and competencies remain up to date, and assurance and verification activities are performed. This article elaborates on these conditions. The reason engineers are required to perform calculations is to support decision-making. Since humans are famously weak natural statisticians, rather than ask stakeholders to implicitly assimilate data, and arrive at a decision, we can instead rely on subject matter experts to explicitly define risk management decision problems. The results of engineering calculation can then also communicate which interventions (if any) are considered to be risk-optimal. It is also proposed that the next generation of engineering standards should learn from the success of open source software development in community building. Interacting with open datasets and code can promote engagement, identification (and resolution) of errors, training and ultimately competence. Finally, the profession's tradition of independent verification should also be applied to the complex models that will increasingly contribute to the safety of the built environment. Model assurance will be required to keep pace with model development to identify suitable use cases as adequately safe. These are considered to be increasingly important components in ensuring that methods of data-centric engineering can be safely and appropriately adopted in industry.},
   author = {Domenic Di Francesco},
   doi = {10.1017/dce.2025.10},
   issn = {26326736},
   journal = {Data-Centric Engineering},
   keywords = {assurance,computational statistics,machine learning,risk management},
   month = {2},
   publisher = {Cambridge University Press},
   title = {Risk management in the era of data-centric engineering},
   volume = {6},
   year = {2025}
}
@article{Lu2020,
   abstract = {Concept drift describes unforeseeable changes in the underlying distribution of streaming data over time. Concept drift research involves the development of methodologies and techniques for drift detection, understanding and adaptation. Data analysis has revealed that machine learning in a concept drift environment will result in poor learning results if the drift is not addressed. To help researchers identify which research topics are significant and how to apply related techniques in data analysis tasks, it is necessary that a high quality, instructive review of current research developments and trends in the concept drift field is conducted. In addition, due to the rapid development of concept drift in recent years, the methodologies of learning under concept drift have become noticeably systematic, unveiling a framework which has not been mentioned in literature. This paper reviews over 130 high quality publications in concept drift related research areas, analyzes up-to-date developments in methodologies and techniques, and establishes a framework of learning under concept drift including three main components: concept drift detection, concept drift understanding, and concept drift adaptation. This paper lists and discusses 10 popular synthetic datasets and 14 publicly available benchmark datasets used for evaluating the performance of learning algorithms aiming at handling concept drift. Also, concept drift related research directions are covered and discussed. By providing state-of-the-art knowledge, this survey will directly support researchers in their understanding of research developments in the field of learning under concept drift.},
   author = {Jie Lu and Anjin Liu and Fan Dong and Feng Gu and Joao Gama and Guangquan Zhang},
   doi = {10.1109/TKDE.2018.2876857},
   month = {4},
   title = {Learning under Concept Drift: A Review},
   url = {http://arxiv.org/abs/2004.05785 http://dx.doi.org/10.1109/TKDE.2018.2876857},
   year = {2020}
}
@techReport{BritishStandardsInstitute2004,
   author = {British Standards Institute},
   isbn = {0580454614},
   title = {BS EN 14015 - Specification for the design and manufacture of site built,
vertical, cylindrical, flat-bottomed, above ground, welded, steel
tanks for the storage of liquids at ambient temperature and
above},
   year = {2004}
}
@techReport{BritishStandardsInstitute2009,
   author = {British Standards Institute},
   isbn = {9780580580000},
   title = {BS EN 1011 - Welding - Recommendations for welding of metallic materials},
   year = {2009}
}
@techReport{BritishStandardsInstitute2021,
   author = {British Standards Institute},
   isbn = {9780539179477},
   title = {BS EN 13445 - Unfired pressure vessels},
   year = {2021}
}
@techReport{BritishStandardsInstitution1987,
   author = {British Standards Institution},
   isbn = {0580159175},
   title = {BS 2633 - Specification for
Class I arc welding of
ferritic steel pipework
for carrying fluids},
   year = {1987}
}
